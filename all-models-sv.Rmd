# Mammal Stroke Volume
## Data

Predictors: body mass interacting with habitat.


### Read in data 

```{r, sv-data-in}
mammal_sv <- read.csv("data/sv.csv") 
```

### Notes

- `log10sv` is the base-10 logarithm of stroke volume in ml

### Cleaning

Rename some variables and create species name from genus and species. 

```{r, sv-data-rename}
mammal_sv <- mammal_sv %>%
  rename(source = Source,
         order = order.corrected,
         mass.kg = body.mass..kg.) %>%
  mutate(order = str_to_title(order),
         genus = str_to_title(genus),
         animal = paste(genus, species),
         above.10kg = ifelse(mass.kg >= 10, 'Larger', 'Smaller'))
```

Keep only variables we will be using. And `factor()` "chr" variables.

```{r, sv-data-select}
mammal_sv <- mammal_sv %>%
  dplyr::select(order,
                genus,
                species, 
                common.name,
                mass.kg,
                log10.body.mass,
                log10sv,
                habitat,
                source,
                animal,
                above.10kg
         ) %>%
  mutate(across(where(is.character), factor)) %>%
  arrange(order, genus, species)
```

### Viz
A few quick graphs just to make sure the data are looking as we expect (error checking).


```{r, sv-create-plot-no-display}
my_scatter_plot <- gf_point(log10sv ~ log10.body.mass | habitat,
         color = ~order,
         # size = ~parse_number(n_animals),
         data = mammal_sv,
         alpha = 0.5) %>%
  gf_theme(legend.position = 'bottom',
           legend.title = element_text(size = 8),
           legend.text = element_text(size = 6)) %>%
  gf_theme(scale_color_viridis_d('Order')) %>%
  gf_labs(x = 'Log10(Mass (kg))',
          y = 'Log10(SV (ml))') 
```

```{r, sv-display-static, warning = FALSE, message = FALSE}
my_scatter_plot
```

```{r, sv-disply-interactive, warning = FALSE, message = FALSE}
plotly::ggplotly(my_scatter_plot) %>%
  plotly::layout(legend = list(#orientation = 'h',
                               font = list(size = 6)))
```

Notes: If we wanted to use for web or publication, we would refine. We can edit what info is shown when you hover over a data point, change color scheme, legend, etc.

## GLS

Will not account for phylogeny at all in the model structure. Predictors: body mass interacting with habitat. Weight by number of individuals (if have data later, don't have it now)?

```{r, sv-fit-lm}
lm_model <- lm(log10sv ~ log10.body.mass * habitat,
                 data = mammal_sv)
summary(lm_model)
tab_model(lm_model) 
lm_anova_results <- car::Anova(lm_model)
pander(lm_anova_results)
```

<!-- For more on formatting the fitted model table see: <https://strengejacke.github.io/sjPlot/articles/tab_model_estimates.html> -->

### Model Assessment

```{r, sv-assess-lm}
lm_preds <- predict(lm_model, se.fit = TRUE)

mammal_sv <- mammal_sv  %>% mutate(lm_resids = resid(lm_model),
         lm_fitted = lm_preds$fit,
         lm_fit_lo = lm_preds$fit + 1.96*lm_preds$se.fit,
         lm_fit_hi = lm_preds$fit - 1.96*lm_preds$se.fit)
gf_point(lm_resids ~ lm_fitted, data = mammal_sv)
acf(resid(lm_model))
gf_dhistogram(~lm_resids, data = mammal_sv,
              bins = 7) %>%
  gf_fitdistr()
```


### Model Predictions

Any predictors *not shown* in a plot are held constant at their mean or most common value.

```{r, sv-predict-lm}
gf_line(lm_fitted ~ log10.body.mass,
         color = ~habitat,
         data = mammal_sv) %>%
  gf_ribbon(lm_fit_lo + lm_fit_hi ~ log10.body.mass,
            color = ~habitat, fill = ~habitat) %>% 
  gf_theme(scale_color_manual(values = my_colors)) %>%
  gf_theme(scale_fill_manual(values = my_colors))

gf_point(log10sv ~ lm_fitted, data = mammal_sv,
         alpha = 0.1) %>%
  gf_labs(y = 'Observed log10(fH)',
          x = 'Model-predicted log10(fH)',
          title = 'Linear Regresssion (no phylogeny)') %>%
  gf_abline(slope = 1, intercept = 0, color = 'black', linetype = 'dashed')
```

Can refine the plot of predictions later on.

## Mixed-effects model 

Will include nested random effects of order/family/genus/species, expecting similarity of observations based on a hierarchy of phylogenetic relatedness, but not in a specified/structured way; only groupings are used, with no sense of (for example) the fact that two orders are thought to be "further" apart than any other two.

```{r, sv-fit-re}
re_model <- glmmTMB(log10sv ~ log10.body.mass * habitat +
                      (1 | order/genus/species),
                 data = mammal_sv)
summary(re_model)
tab_model(re_model) 
re_anova_results <- car::Anova(re_model)
pander(re_anova_results)
```

### Model Assessment

```{r, sv-assess-re}
re_ave_preds <- predict(re_model, 
                    se.fit = TRUE,
                    re.form = ~0)
re_ind_preds <- predict(re_model,
                        se.fit = TRUE,
                        re.form = NULL)
mammal_sv <- mammal_sv %>%
  mutate(re_resids = resid(re_model),
         re_ind_fitted = re_ind_preds$fit,
         re_ave_fitted = re_ave_preds$fit,
         re_ave_lo = re_ave_preds$fit - 1.96*re_ave_preds$se.fit,
         re_ave_hi = re_ave_preds$fit + 1.96*re_ave_preds$se.fit)
gf_point(re_resids ~ re_ind_fitted, data = mammal_sv)

# save fitted model and data
saveRDS(mammal_sv, 'fitted-models/sv-data.RDS')
saveRDS(re_model, 'fitted-models/sv-re-model.RDS')


acf(resid(re_model))
acf(resid(re_model))
gf_dhistogram(~re_resids, data = mammal_sv,
              bins = 7) %>%
  gf_fitdistr()
```

### Predictions from Model

```{r, sv-predict-re}
mammal_sv <- mammal_sv %>%
  mutate(Habitat = stringr::str_to_sentence(habitat))

re_preds <- gf_point(10^log10sv ~ 10^log10.body.mass,
         color = ~Habitat,
        text = ~animal,
         data = mammal_sv) %>% 
  gf_line(10^re_ave_fitted ~ 10^log10.body.mass,
         color = ~Habitat,
         data = mammal_sv,
         text = ~Habitat) %>%
  gf_ribbon(10^re_ave_lo + 10^re_ave_hi ~ 10^log10.body.mass,
            color = ~Habitat, fill = ~Habitat, 
            text = ~Habitat) %>% 
  gf_labs(x = 'Body Mass (kg)', y = 'Stroke Volume (mL/beat)') %>% 
  gf_theme(scale_color_manual(values = my_colors)) %>%
  gf_theme(scale_fill_manual(values = my_colors)) %>%
  gf_refine(scale_x_continuous(trans = 'log10',
                               labels = scales::label_comma(accuracy = 0.001,
                                                            drop0trailing = TRUE)),
            scale_y_continuous(trans = 'log10',
                               labels = scales::label_comma(accuracy = 0.001,
                                                            drop0trailing = TRUE))
  )

# For stroke volume (Stahl 1967, using prediction equations from Stahl for cardiac output (ml/min) and heat rate(beats/min)): SV (ml/beat) = [187 * body mass(kg)^0.81]/[241 * body mass (kg) ^-0.25]

pub_models <- data.frame(mass = seq(from = 0.001, by = 10, to = 70000)) %>% # data.frame(mass = seq(from = 0.029, by = 0.1, to = 5000)) %>%
  mutate(sv_stahl = (187*mass^0.81) / (241 * mass^-0.25))

re_preds <- re_preds %>%
  gf_line(sv_stahl ~ mass, data = pub_models, color = 'black',
          text = ~'Stahl') %>%
  # c(0,0) corresponds to the “bottom left” and c(1,1) corresponds to the “top right” position
  gf_theme(legend.position = c(0.9, 0.1),
           legend.title = element_blank()) %>%
  gf_theme(plot.margin = unit(c(1,2,1,1), "cm"))
```

```{r, fig.cap = 'Observed and predicted stroke volume as a function of mass and habitat. Lines are model predictions, points are observed data, and shaded areas are 95% confidence intervals. Colored lines are predictions from the mixed-effects model, green for terrestrial and blue for aquatic; black solid line is based on Stahl (1967).', fig.width = 6.5, fig.height = 3.5}
re_preds %>% gf_theme(legend.position='none') %>% ggplotly(tooltip = 'text')
```

```{r, sv-re-predictions, echo = FALSE, fig.show = 'hide', dev = 'jpeg'}
re_preds
```

```{r, pred-vs-fitted}
gf_point(log10sv ~ re_ind_fitted, data = mammal_sv,
         alpha = 0.1) %>%
  gf_labs(y = 'Observed log10(sv)',
          x = 'Model-predicted, Species-specific log10(sv)',
          title = 'Mixed-effects Model (RE of Order/Genus/Species)') %>%
  gf_abline(slope = 1, intercept = 0, color = 'black', linetype = 'dashed')
```



## PGLS

```{r, sv-setup-trees, message = FALSE}
#Read in the trees from Upham et al

tree_path <- paste("data/upham-trees/Completed_5911sp_topoCons_FBDasZhouEtAl")
tree_files <- list.files(tree_path)


all_trees <- list()

for (i in 1:length(tree_files)){
  all_trees[[i]] <- read.tree(paste0(tree_path, '/',
                                     tree_files[i]))
  if (i == 1){
    treeset <- all_trees[[i]]
  }else{
    treeset <- c(treeset, all_trees[[i]])
  }
}

all_tip_labels <- purrr::map(treeset, "tip.label")
all_tip_labels <- purrr::map(all_tip_labels,
                             function(x) 
                               stringr::str_replace_all(x, pattern = '_',
                                                      replacement = ' '))

# get list of species that are in ALL the trees
for (t in 1:length(all_tip_labels)){
  if (t == 1){
    tip_labs <- all_tip_labels[[t]]
  }else{
    tip_labs <- intersect(tip_labs, all_tip_labels[[t]])
  }
}


                            
# keep only the species in mammal_sv that are in all the trees
# on 6/17 this removes NO species.
pgls_data <- mammal_sv %>%
  mutate(animal = as.character(animal)) %>%
  filter(animal %in% tip_labs) %>%
  droplevels()


taxonomy <- read_csv('data/upham-trees/taxonomy_mamPhy_5911species.csv')

```

Fit models, one model for every tree in our list.

```{r, sv-fit-pgls}
pgls_models <- list()

for (t in c(1:length(treeset))){
  # make sure there is only one row of data per species
  pgls_rep_data <- pgls_data %>% 
    group_by(animal) %>%
    sample_n(1) %>%
    ungroup
  
  
  #Reduce the tree to only include those species in the data set
  refit_tree <- treeset[[t]]
  refit_tree$tip.label <- str_replace_all(refit_tree$tip.label, '_', ' ')
  refit_tree <- drop.tip(refit_tree, 
                         setdiff(refit_tree$tip.label, 
                                 unique(pgls_rep_data %>% pull(animal))))
  
  #Order the data set so that it is in the same order as the tip labels of the tree
  pgls_rep_data <- left_join(data.frame(tree.tip.label = refit_tree$tip.label),
                             pgls_rep_data,
                             by = c('tree.tip.label' = 'animal'),
                             keep = TRUE)
  
  # fit the model
 pgls_models[[t]] <- tryCatch({
    fittd <- gls(log10sv ~ log10.body.mass * habitat,
                 correlation = corPagel(value = 0.8, 
                                        phy = refit_tree, 
                                        fixed = FALSE, 
                                        form = ~animal),
                 data = pgls_rep_data)
  },
  error = function(cond){
    message(paste('PGLS fit failed for tree', t))
    return(NULL)
  }
  )
}

pgls_models <- pgls_models[!sapply(pgls_models, is.null)]
```

Note: we tried to fit `r length(treeset)` PGLS models (each with a different tree); of these, model fitting failed for `r length(treeset) - length(pgls_models)`.

Combine the many PGLS model runs together into one summary combined model according to Rubin's rule.

```{r, sv-test-pgls}
# as.mira takes the list of models and create an object to be used by the mice package
pgls_mira <- as.mira(pgls_models)  
# # pool summarise the models using Rubin's rule corrected for small samples
pooled_pgls   <- pool(pgls_mira)
pooled_pgls_summ <- summary(pooled_pgls, type = 'all', conf.int = TRUE)

pander(pooled_pgls_summ %>% dplyr::select(term, estimate, std.error, `2.5 %`, `97.5 %`, lambda, fmi))


# this depends on inner workings of package car found in gls-utils.R
# it used to work without all this, in summer 2021 stopped
pgls_anova <- Anova(pgls_mira)
pander(pgls_anova)


```

Alternative approach: using `MuMIn` to do model averaging. Was it right to weight all of the models/trees equally?

```{r, sv-avg-pgls}
pgls_avg <- model.avg(pgls_models, 
                      rank = function(x) 1)
```

This gives a model with the same coefficients (same model) that we can better make `predict()`ions from. 

For the PGLS model, we also want to extract the estimate of $\Lambda$, which tells us about how the phylogeny is affecting the correlation structure.

Simple approach: take the mean of the estimates of $\Lambda$ from all the individual fitted models.

```{r, sv-get-lambda}
lambda <- mean(unlist(purrr::map(pgls_models, function(x) x$modelStruct$corStruct)))
lambda
```

### Model Assessment


It's not really clear how to even approach this, since we don't really any longer expect the residuals to be normal or independent. And based on the data we know there's not a huge issue with linearity. So...ok?
